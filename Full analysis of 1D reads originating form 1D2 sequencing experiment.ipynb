{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of 1D reads\n",
    "\n",
    "## 1) Recovery 1D reads with a Phred quality > 5\n",
    "    Retrieve all 1D reads with q >= 5 (the 1D reads from a 1D2 run are not split into pass/fail groups)\n",
    "## 2) Split reads per sample using barcodes to identify each sample\n",
    "    Using a fuzzy regex allowing for 3 mismatches \n",
    "## 3) Mapping of the reads against the reference\n",
    "    Direct mapping using the ont2d settings against the references SNP regions (51 nt)\n",
    "## 4) Detemine the SNP genotype on position 26 in the mappings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1) Recovery of 1D reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "#\n",
    "import os, glob\n",
    "import regex\n",
    "from multiprocessing import Pool\n",
    "\n",
    "rawDataDir       = '/media/genomics/nanopore/run_data/20171219_nanopore_tri-allelic-1D2_basecalled_albacore-2.1.3'\n",
    "projectDir       = '/media/genomics/nanopore/projects/tri-allelic_SNPs/20171220_nanopore_1d2_analysis/Github'\n",
    "rawDataQCDir     = os.path.join(projectDir, 'raw_data_qc_albacore-2.1.3')\n",
    "resultDir        = os.path.join(projectDir, 'one_d_read_analysis_q5_or_better')\n",
    "oneDFastqFile    = os.path.join(rawDataDir, 'workspace', 'fastq_runid_d4e8a3e33e86f12065040abb8f96841c1613b6b3.fastq')\n",
    "snpRefFile       = os.path.join(projectDir, 'triallelic_snp_regions.fasta')\n",
    "barcodeFile      = os.path.join(projectDir, 'barcodes_tri-allelic.csv')\n",
    "snpRefFile       = os.path.join(projectDir, 'triallelic_snp_regions.fasta')\n",
    "sampleMap        = {\n",
    "  'NB07': '9948',\n",
    "  'NB08': '9947',\n",
    "  'NB09': '2800',\n",
    "  'NB10': 'Gednap50_Person_C',\n",
    "  'NB12': 'Gednap51_Person_C'   \n",
    "}\n",
    "\n",
    "nanofilt   = 'NanoFilt'\n",
    "nanoplot   = 'NanoPlot'\n",
    "bwa        = '/opt/tools/bwa-0.7.15'\n",
    "samtools   = '/opt/tools/samtools-1.3.1'\n",
    "bcftools   = '/opt/tools/bcftools-1.3.1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! {nanofilt} --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5Done\n"
     ]
    }
   ],
   "source": [
    "# Rescue 1D reads with q factor 5 or better\n",
    "#\n",
    "oneDFastqQ5File = os.path.join(resultDir, os.path.basename(oneDFastqFile).replace('.fastq', '_q5.fastq'))\n",
    "\n",
    "! cat {oneDFastqFile} | {nanofilt} -q 5 --readtype 1D > {oneDFastqQ5File}\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D reads (all q):             1119243\n",
      "Recovered 1D reads having q >= 5:       806463\n"
     ]
    }
   ],
   "source": [
    "# Original 1d (all q)\n",
    "r = ! wc -l {oneDFastqFile}\n",
    "count = int(r[0].split(' ')[0]) // 4\n",
    "print('Original 1D reads (all q):        {:>12d}'.format(count))\n",
    "\n",
    "# Recovered 1d (q => 5)\n",
    "r = ! wc -l {oneDFastqQ5File}\n",
    "count = int(r[0].split(' ')[0]) // 4\n",
    "print('Recovered 1D reads having q >= 5: {:>12d}'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Generate quality score plots\n",
    "\n",
    "# Rescued reads\n",
    "! {nanoplot} -t 10 --maxlength 3000 --fastq_rich {oneDFastqQ5File} -o {rawDataQCDir} -p 'recovered_q5_one_d_'\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Split reads per sample using barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "#\n",
    "def reverseComplement(seq):\n",
    "  transTab = str.maketrans('agctyrwskmdvhbAGCTYRWSKMDVHB', 'tcgarywsmkhbdvTCGARYWSMKHBDV')\n",
    "  return seq.translate(transTab)[::-1]\n",
    "\n",
    "\n",
    "\n",
    "def loadReads(fileName):\n",
    "  \"\"\"\n",
    "  Return a dict with the sequencing reads (including quality scores) extracted from the given file\n",
    "  \"\"\"\n",
    "  rData = {}\n",
    "  with open(fileName, 'rt') as f:\n",
    "    cnt = 0\n",
    "\n",
    "    for line in f:\n",
    "      cnt += 1\n",
    "      if cnt % 4 == 1:\n",
    "        readName = line.rstrip()\n",
    "      elif cnt % 4 == 2:\n",
    "        readSeq = line.rstrip()\n",
    "      elif cnt % 4 == 0:\n",
    "        readQual = line.rstrip()\n",
    "        rData[readName] = {'s': readSeq, 'q': readQual}\n",
    "        if len(rData[readName]['s'])==0 or len(rData[readName]['q'])==0:\n",
    "          print('*** Partial read data: {}'.format(readName))\n",
    "            \n",
    "  return(rData)\n",
    "\n",
    "\n",
    "\n",
    "def findBarcodes(readName):\n",
    "  \"\"\"\n",
    "  Lookup all barcodes in the given read. Return a dict with the barcode hit counts for all reads.\n",
    "  \"\"\"\n",
    "  barcodeHits = {}\n",
    "  \n",
    "  for barcodeName in barcodeList:\n",
    "    # Lookup forward barcode sequence\n",
    "    for pattern in (barcodeRE[barcodeName]['f'], barcodeRE[barcodeName]['r']):\n",
    "      for match in pattern.finditer(readData[readName]['s']):\n",
    "        if readName not in barcodeHits:\n",
    "          barcodeHits[readName] = {}\n",
    "        if barcodeName not in barcodeHits[readName]:\n",
    "          barcodeHits[readName][barcodeName] = 1\n",
    "        else:\n",
    "          barcodeHits[readName][barcodeName] += 1\n",
    "          \n",
    "  return barcodeHits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load barcode data, compile regex\n",
    "#\n",
    "# Get the barcodes\n",
    "#\n",
    "barcodeList = {}\n",
    "barcodeRE   = {}\n",
    "maxMisMatch = 3\n",
    "\n",
    "with open(barcodeFile, 'rt') as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Ignore the column header line (should start with a '#')\n",
    "    if line.startswith('#'):\n",
    "      continue\n",
    "      \n",
    "    # Store\n",
    "    name, seq         = line.split(',')\n",
    "    barcodeList[name] = {'f': seq, 'r': reverseComplement(seq)}\n",
    "    \n",
    "    barcodeRE[name] = {\n",
    "      'f': regex.compile('(?e)({}){{e<={}}}'.format(barcodeList[name]['f'], maxMisMatch)),\n",
    "      'r': regex.compile('(?e)({}){{e<={}}}'.format(barcodeList[name]['r'], maxMisMatch))\n",
    "    }\n",
    "    \n",
    "print('Found {} barcodes:'.format(len(barcodeList)))\n",
    "for n in sorted(barcodeList):\n",
    "  print(n, barcodeList[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load 1D read data\n",
    "#\n",
    "readDataOneDQ5 = loadReads(oneDFastqQ5File)\n",
    "\n",
    "print('Loaded {} 1D reads'.format(len(readDataOneDQ5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify barcodes in 1D reads\n",
    "#\n",
    "barcodeHitData1D  = {}\n",
    "readData          = readDataOneDQ5\n",
    "maxThread         = 20\n",
    "pool              = Pool(maxThread)\n",
    "bcHitList         = pool.map(findBarcodes, readDataOneDQ5.keys())  # list of {readname: {barcodename: hitcount}}\n",
    "pool.terminate()\n",
    "\n",
    "for d in bcHitList:\n",
    "  barcodeHitData1D.update(d)\n",
    "\n",
    "# Print stats\n",
    "barcodeStats1D = {}\n",
    " \n",
    "for readName in barcodeHitData1D:\n",
    "  n = 'reads having {} barcodes'.format(len(barcodeHitData1D[readName]))\n",
    "  if n in barcodeStats1D:\n",
    "    barcodeStats1D[n] += 1\n",
    "  else:\n",
    "    barcodeStats1D[n] = 1\n",
    "  \n",
    "  for barcodeName in barcodeHitData1D[readName]:\n",
    "    if barcodeName in barcodeStats1D:\n",
    "      barcodeStats1D[barcodeName] += 1\n",
    "    else:\n",
    "      barcodeStats1D[barcodeName] = 1\n",
    "\n",
    "for k in sorted(barcodeStats1D.keys()):\n",
    "  print('{} = {} ({:>.1f}%)'.format(k, barcodeStats1D[k], 100*barcodeStats1D[k]/len(readDataOneDQ5)))\n",
    "  \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save 1D reads in fastq files per barcode (sample).  We keep only reads that have 1 type of barcode.\n",
    "\n",
    "outFiles = {}\n",
    "\n",
    "for readName in barcodeHitData1D:\n",
    "  if len(barcodeHitData1D[readName]) == 1:\n",
    "    for barcodeName in barcodeHitData1D[readName]:\n",
    "      if barcodeName not in outFiles:\n",
    "        fastqFileName = os.path.join(resultDir, '{}.fastq'.format(barcodeName))\n",
    "        outFiles[barcodeName] = open(fastqFileName, 'wt')\n",
    "        print('Created {}'.format(fastqFileName))\n",
    "      \n",
    "      # Write fastq read\n",
    "      outFiles[barcodeName].write('{}\\n{}\\n+\\n{}\\n'.format(readName, readDataOneDQ5[readName]['s'], readDataOneDQ5[readName]['q']))\n",
    "      \n",
    "# Close files (required, otherwise buffers are not always flushed to disk!)\n",
    "for barcodeName in outFiles:\n",
    "  outFiles[barcodeName].close()\n",
    "  \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count 1D reads per barcode (sample)\n",
    "#\n",
    "barcodeList  = ['NB07', 'NB08', 'NB09', 'NB10', 'NB12']\n",
    "barcodeReads = {}\n",
    "totalReads   = len(readDataOneDQ5)\n",
    "\n",
    "print('Total reads: {}'.format(totalReads))\n",
    "\n",
    "for barcodeName in barcodeList:\n",
    "  fastqFileName             = os.path.join(resultDir, '{}.fastq'.format(barcodeName))\n",
    "  barcodeReads[barcodeName] = loadReads(fastqFileName)\n",
    "  readCount                 = len(barcodeReads[barcodeName])\n",
    "  \n",
    "  print('{}: {} ({} %) reads'.format(barcodeName, readCount, 100*readCount/totalReads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Mapping of the reads against the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snpRefFile    = os.path.join(projectDir, 'triallelic_snp_regions.fasta')\n",
    "sampleMap     = {\n",
    "  'NB07': '9948',\n",
    "  'NB08': '9947',\n",
    "  'NB09': '2800',\n",
    "  'NB10': 'Gednap50_Person_C',\n",
    "  'NB12': 'Gednap51_Person_C'  \n",
    "}\n",
    "\n",
    "bwa        = '/opt/tools/bwa-0.7.15'\n",
    "samtools   = '/opt/tools/samtools-1.3.1'\n",
    "bcftools   = '/opt/tools/bcftools-1.3.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index reference\n",
    "#\n",
    "! {bwa} index {snpRefFile}\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map amplicons to reference SNP region sequences (51 nt), call variants\n",
    "#\n",
    "for sampleName in sorted(sampleMap):\n",
    "  # Map amplicons\n",
    "  fastqFile = os.path.join(resultDir, '{}.fastq'.format(sampleName))\n",
    "  fastaFile = os.path.join(resultDir, '{}_noqual.fasta'.format(sampleName))\n",
    "  bamFile   = fastaFile.replace('.fasta', '_direct_mapping.bam')\n",
    "  vcfFile   = fastaFile.replace('.fasta', '_direct_mapping.vcf')\n",
    "  \n",
    "  # Convert fastq to fasta\n",
    "  ! paste - - - - < {fastqFile} | cut -f 1,2 | sed 's/^@/>/' | tr \"\\t\" \"\\n\" > {fastaFile}\n",
    "  \n",
    "  # Map\n",
    "  ! {bwa} mem -t 10 -x ont2d {snpRefFile} {fastaFile} | {samtools} view -Sb - | {samtools} sort -o {bamFile} -\n",
    "  ! {samtools} index {bamFile}\n",
    "  \n",
    "  # Variant calling\n",
    "  !{samtools} mpileup -d 100000 -Buf {snpRefFile} -t AD {bamFile} | {bcftools} call -V indels -m - > {vcfFile}\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Detemine the SNP genotype on position 26 in the mappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genotype(vcfFile, snpPos):\n",
    "  \"\"\"\n",
    "  Extract genotype data at given position from a given vcf file.\n",
    "  \"\"\"\n",
    "  genotypeData = {}\n",
    "  \n",
    "  with open (vcfFile, 'rt') as inFile:\n",
    "    for line in inFile:\n",
    "      if line.startswith('#'): continue\n",
    "      \n",
    "      snpName, pos, id, ref, alt, qual, filt, info, form, formValues = line.rstrip().split()\n",
    "      \n",
    "      if int(pos) == snpPos:\n",
    "        k        = form.split(':')\n",
    "        v        = formValues.split(':')         \n",
    "        formData = {}\n",
    "        \n",
    "        for i in range(len(k)):\n",
    "          formData[k[i]] = v[i]\n",
    "          \n",
    "        infoData = {}\n",
    "        for t in info.split(';'):\n",
    "          k,v = t.split('=')\n",
    "          infoData[k] = v\n",
    "          \n",
    "        alleles = ref\n",
    "        if alt != '.':\n",
    "          alleles += ''.join(alt.split(','))\n",
    "          \n",
    "        depths                = [int(d) for d in formData['AD'].split(',')]\n",
    "        gt                    = [alleles[int(i)] for i in formData['GT'].split('/') ]\n",
    "        genotypeData[snpName] = {'pos': pos, 'alleles': {'A': 0, 'G': 0, 'C': 0, 'T':0}, 'genotype': '/'.join(gt), 'depth': int(infoData['DP'])}\n",
    "        \n",
    "        for i in range(len(alleles)):\n",
    "          genotypeData[snpName]['alleles'][alleles[i]] = depths[i]\n",
    "        \n",
    "  return genotypeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all sample genotypes\n",
    "#\n",
    "excludeSnp = [] \n",
    "genotypes  = {}\n",
    "\n",
    "for sampleName in sorted(sampleMap, key=lambda k: sampleMap[k]):\n",
    "  print(\"SNP's for sample {} ({})\".format(sampleName, sampleMap[sampleName]))\n",
    "  genotypes[sampleName] = {}\n",
    "  vcfFile               = os.path.join(resultDir, '{}_noqual_direct_mapping.vcf'.format(sampleName))\n",
    "  \n",
    "  d = genotype(vcfFile, 26)\n",
    "  \n",
    "  for snpName in sorted(d):\n",
    "    t = sum(d[snpName]['alleles'].values())\n",
    "    \n",
    "    # Likely genotype\n",
    "    gg = {}\n",
    "    vv = sorted([int(c) for c in d[snpName]['alleles'].values()], reverse=True)\n",
    "    \n",
    "    for g, c in d[snpName]['alleles'].items():\n",
    "      if c not in gg:\n",
    "        gg[c] = [g]\n",
    "      else:\n",
    "        gg[c].append(g)\n",
    "    # Second allele must be at least 25% of main allele or it is ignored.\n",
    "    if len(vv) > 1 and vv[1] > vv[0]/4:\n",
    "      if len(gg[vv[0]]) > 1:\n",
    "        aa = ''.join(gg[vv[0]])\n",
    "      else:\n",
    "        aa = gg[vv[0]][0] + gg[vv[1]][0]\n",
    "    else:\n",
    "      aa = gg[vv[0]][0] + gg[vv[0]][0]\n",
    "    \n",
    "    o = '  {:<14}  '.format(snpName)\n",
    "    \n",
    "    for g in sorted(d[snpName]['alleles']):\n",
    "      o += '  {}:{:<5}'.format(g, d[snpName]['alleles'][g])\n",
    "    for g in sorted(d[snpName]['alleles']):\n",
    "      if t > 0:\n",
    "        o += '  {}:{:>3}%'.format(g, round(100*d[snpName]['alleles'][g]/t))\n",
    "      else:\n",
    "        o += '  {}:{:>3}%'.format(g, '???')\n",
    "    o += '    {:>5}/{:<5} reads'.format(t, d[snpName]['depth'])\n",
    "    o += '    {}'.format(''.join(sorted(aa)))\n",
    "    genotypes[sampleName][snpName] = ''.join(sorted(aa))\n",
    "    print(o)\n",
    "  \n",
    "  print('')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Genotype overview\n",
    "#\n",
    "h = 'SNP           '\n",
    "snpNames = set()\n",
    "\n",
    "sortedSampleNames = sorted(sampleMap, key=lambda k: sampleMap[k])\n",
    "\n",
    "for sampleName in sortedSampleNames:\n",
    "  h += ' {:>10}'.format(sampleMap[sampleName])\n",
    "  \n",
    "  for snpName in genotypes[sampleName]:\n",
    "    snpNames.add(snpName)\n",
    "print(h)\n",
    "\n",
    "for snpName in sorted(snpNames):\n",
    "  r = '{:<14}'.format(snpName)\n",
    "  \n",
    "  for sampleName in sortedSampleNames:\n",
    "    if snpName in genotypes[sampleName]:\n",
    "      aa = ''.join(sorted(genotypes[sampleName][snpName]))\n",
    "    else:\n",
    "      aa = ''\n",
    "    r += ' {:>10}'.format(aa)\n",
    "    \n",
    "    \n",
    "  print(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
