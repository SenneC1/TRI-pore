{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of 1D reads\n",
    "\n",
    "## 1) Recover 1D2 reads with a Phred Quality > 10\n",
    "    Retrieve all 1D reads with q >= 10 (the 1D2 reads with q<11 are normally split into the fail group)\n",
    "    No new basecalling, we just filter the better reads from the fail set using NanoFilter\n",
    "## 2) Split reads per sample using barcodes to identify each sample\n",
    "    Using a fuzzy regex allowing for 3 mismatches \n",
    "## 3) Mapping of the reads against the reference\n",
    "    Direct mapping using the ont2d settings against the references SNP regions (51 nt)\n",
    "## 4) Detemine the SNP genotype on position 26 in the mappings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Recover q10 1D2 reads and combine with original 1D2 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "#\n",
    "import os, glob\n",
    "import regex\n",
    "from multiprocessing import Pool\n",
    "\n",
    "rawDataDir       = '/media/genomics/nanopore/run_data/20171219_nanopore_tri-allelic-1D2_basecalled_albacore-2.1.3'\n",
    "projectDir       = '/media/genomics/nanopore/projects/tri-allelic_SNPs/20171220_nanopore_1d2_analysis/Github'\n",
    "resultDir        = os.path.join(projectDir, 'one_d_squared_read_analysis_q10_or_better')\n",
    "pass1dsqFastqDir = os.path.join(rawDataDir, '1dsq_analysis', 'workspace', 'pass')\n",
    "fail1dsqFastqDir = os.path.join(rawDataDir, '1dsq_analysis', 'workspace', 'fail')\n",
    "q10R1dsqFastqDir = os.path.join(rawDataDir, '1dsq_analysis', 'workspace', 'filter_q10')\n",
    "rawDataQCDir     = os.path.join(projectDir, 'raw_data_qc_albacore-2.1.3')\n",
    "barcodeFile      = os.path.join(projectDir, 'barcodes_tri-allelic.csv')\n",
    "\n",
    "nanoplot         = 'NanoPlot' # v1.8.1 (in p36 venv YG)\n",
    "\n",
    "if not os.path.exists(resultDir):\n",
    "  print('Creating directory {}'.format(resultDir))\n",
    "  os.makedirs(resultDir)\n",
    "else:\n",
    "  print('Directory {} exists'.format(resultDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D2 reads having q >= 11:  4407\n",
      "Recovered 1D2 reads having q >= 10: 8405\n"
     ]
    }
   ],
   "source": [
    "# Count reads\n",
    "#\n",
    "\n",
    "# Original 1d2 (q >= 11)\n",
    "r = ! wc -l {os.path.join(pass1dsqFastqDir, '*.fastq')}\n",
    "count = int(r[0].split(' ')[0]) // 4\n",
    "print('Original 1D2 reads having q >= 11:  {}'.format(count))\n",
    "\n",
    "# Recovered 1d2 (10 <= q < 11)\n",
    "r = ! wc -l {os.path.join(q10R1dsqFastqDir, '*_filter_failed_1dsq_q10.fastq')}\n",
    "count = int(r[0].split(' ')[0]) // 4\n",
    "print('Recovered 1D2 reads having q >= 10: {}'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 1D2 reads having q >= 10: 12812\n"
     ]
    }
   ],
   "source": [
    "# Combine with original 1D2 reads\n",
    "#\n",
    "combined1dsqFastq = os.path.join(q10R1dsqFastqDir, 'combined_1dsq_q10_or_better.fastq')\n",
    "\n",
    "! cat {os.path.join(pass1dsqFastqDir, '*.fastq')} {os.path.join(q10R1dsqFastqDir, '*_filter_failed_1dsq_q10.fastq')} > {combined1dsqFastq}\n",
    "\n",
    "r = ! wc -l {combined1dsqFastq}\n",
    "count = int(r[0].split(' ')[0]) // 4\n",
    "print('Combined 1D2 reads having q >= 10: {}'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Generate quality score plots\n",
    "#\n",
    "\n",
    "# Rescued reads\n",
    "! {nanoplot} -t 10 --maxlength 3000 --fastq_rich {os.path.join(q10R1dsqFastqDir, '*_filter_failed_1dsq_q10.fastq')} -o {rawDataQCDir} -p 'recovered_q10_one_d_sq_'\n",
    "\n",
    "# Combined reads\n",
    "! {nanoplot} -t 10 --maxlength 3000 --fastq_rich {combined1dsqFastq} -o {rawDataQCDir} -p 'q10_or_better_one_d_sq_'\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Split reads per sample using barcodes to identify each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "#\n",
    "def reverseComplement(seq):\n",
    "  transTab = str.maketrans('agctyrwskmdvhbAGCTYRWSKMDVHB', 'tcgarywsmkhbdvTCGARYWSMKHBDV')\n",
    "  return seq.translate(transTab)[::-1]\n",
    "\n",
    "\n",
    "\n",
    "def loadReads(fileName):\n",
    "  \"\"\"\n",
    "  Return a dict with the sequencing reads (including quality scores) extracted from the given file\n",
    "  \"\"\"\n",
    "  rData = {}\n",
    "  with open(fileName, 'rt') as f:\n",
    "    cnt = 0\n",
    "\n",
    "    for line in f:\n",
    "      cnt += 1\n",
    "      if cnt % 4 == 1:\n",
    "        readName = line.rstrip()\n",
    "      elif cnt % 4 == 2:\n",
    "        readSeq = line.rstrip()\n",
    "      elif cnt % 4 == 0:\n",
    "        readQual = line.rstrip()\n",
    "        rData[readName] = {'s': readSeq, 'q': readQual}\n",
    "        if len(rData[readName]['s'])==0 or len(rData[readName]['q'])==0:\n",
    "          print('*** Partial read data: {}'.format(readName))\n",
    "            \n",
    "  return(rData)\n",
    "\n",
    "\n",
    "\n",
    "def findBarcodes(readName):\n",
    "  \"\"\"\n",
    "  Lookup all barcodes in the given read. Return a dict with the barcode hit counts for all reads.\n",
    "  \"\"\"\n",
    "  barcodeHits = {}\n",
    "  \n",
    "  for barcodeName in barcodeList:\n",
    "    # Lookup forward barcode sequence\n",
    "    for pattern in (barcodeRE[barcodeName]['f'], barcodeRE[barcodeName]['r']):\n",
    "      for match in pattern.finditer(readData[readName]['s']):\n",
    "        if readName not in barcodeHits:\n",
    "          barcodeHits[readName] = {}\n",
    "        if barcodeName not in barcodeHits[readName]:\n",
    "          barcodeHits[readName][barcodeName] = 1\n",
    "        else:\n",
    "          barcodeHits[readName][barcodeName] += 1\n",
    "          \n",
    "  return barcodeHits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load barcode data, compile regex\n",
    "#\n",
    "# Get the barcodes\n",
    "#\n",
    "barcodeList = {}\n",
    "barcodeRE   = {}\n",
    "maxMisMatch = 3\n",
    "\n",
    "with open(barcodeFile, 'rt') as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Ignore the column header line (should start with a '#')\n",
    "    if line.startswith('#'):\n",
    "      continue\n",
    "      \n",
    "    # Store\n",
    "    name, seq         = line.split(',')\n",
    "    barcodeList[name] = {'f': seq, 'r': reverseComplement(seq)}\n",
    "    \n",
    "    barcodeRE[name] = {\n",
    "      'f': regex.compile('(?e)({}){{e<={}}}'.format(barcodeList[name]['f'], maxMisMatch)),\n",
    "      'r': regex.compile('(?e)({}){{e<={}}}'.format(barcodeList[name]['r'], maxMisMatch))\n",
    "    }\n",
    "    \n",
    "print('Found {} barcodes:'.format(len(barcodeList)))\n",
    "for n in sorted(barcodeList):\n",
    "  print(n, barcodeList[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12812 1D2 reads\n"
     ]
    }
   ],
   "source": [
    "# Load 1D2 read data\n",
    "#\n",
    "fastqFile              = os.path.join(q10R1dsqFastqDir, 'combined_1dsq_q10_or_better.fastq')\n",
    "readDataOneDSquaredQ10 = loadReads(fastqFile)\n",
    "\n",
    "print('Loaded {} 1D2 reads'.format(len(readDataOneDSquaredQ10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify barcodes in 1D2 reads\n",
    "#\n",
    "barcodeHitData1D2 = {}\n",
    "readData          = readDataOneDSquaredQ10\n",
    "maxThread         = 20\n",
    "pool              = Pool(maxThread)\n",
    "bcHitList         = pool.map(findBarcodes, readDataOneDSquaredQ10.keys())  # list of {readname: {barcodename: hitcount}}\n",
    "pool.terminate()\n",
    "\n",
    "for d in bcHitList:\n",
    "  barcodeHitData1D2.update(d)\n",
    "\n",
    "# Print stats\n",
    "barcodeStats1D2 = {}\n",
    " \n",
    "for readName in barcodeHitData1D2:\n",
    "  n = 'reads having {} barcodes'.format(len(barcodeHitData1D2[readName]))\n",
    "  if n in barcodeStats1D2:\n",
    "    barcodeStats1D2[n] += 1\n",
    "  else:\n",
    "    barcodeStats1D2[n] = 1\n",
    "  \n",
    "  for barcodeName in barcodeHitData1D2[readName]:\n",
    "    if barcodeName in barcodeStats1D2:\n",
    "      barcodeStats1D2[barcodeName] += 1\n",
    "    else:\n",
    "      barcodeStats1D2[barcodeName] = 1\n",
    "\n",
    "for k in sorted(barcodeStats1D2.keys()):\n",
    "  print('{} = {} ({:>.1f}%)'.format(k, barcodeStats1D2[k], 100*barcodeStats1D2[k]/len(readDataOneDSquaredQ10)))\n",
    "  \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save 1D2 reads in fastq files per barcode (sample).  We keep only reads that have 1 type of barcode.\n",
    "#\n",
    "outFiles = {}\n",
    "\n",
    "for readName in barcodeHitData1D2:\n",
    "  if len(barcodeHitData1D2[readName]) == 1:\n",
    "    for barcodeName in barcodeHitData1D2[readName]:\n",
    "      if barcodeName not in outFiles:\n",
    "        fastqFileName = os.path.join(resultDir, '{}.fastq'.format(barcodeName))\n",
    "        outFiles[barcodeName] = open(fastqFileName, 'wt')\n",
    "        print('Created {}'.format(fastqFileName))\n",
    "      \n",
    "      # Write fastq read\n",
    "      outFiles[barcodeName].write('{}\\n{}\\n+\\n{}\\n'.format(readName, readDataOneDSquaredQ10[readName]['s'], readDataOneDSquaredQ10[readName]['q']))\n",
    "      \n",
    "# Close files (required, otherwise buffers are not always flushed to disk!)\n",
    "for barcodeName in outFiles:\n",
    "  outFiles[barcodeName].close()\n",
    "  \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count 1D2 reads per barcode (sample)\n",
    "#\n",
    "barcodeList  = ['NB07', 'NB08', 'NB09', 'NB10', 'NB12']\n",
    "barcodeReads = {}\n",
    "totalReads   = len(readDataOneDSquaredQ10)\n",
    "\n",
    "print('Total reads: {}'.format(totalReads))\n",
    "\n",
    "for barcodeName in barcodeList:\n",
    "  fastqFileName             = os.path.join(resultDir, '{}.fastq'.format(barcodeName))\n",
    "  barcodeReads[barcodeName] = loadReads(fastqFileName)\n",
    "  readCount                 = len(barcodeReads[barcodeName])\n",
    "  \n",
    "  print('{}: {} ({} %) reads'.format(barcodeName, readCount, 100*readCount/totalReads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Mapping of the reads against the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snpRefFile    = os.path.join(projectDir, 'triallelic_snp_regions.fasta')\n",
    "sampleMap     = {\n",
    "  'NB07': '9948',\n",
    "  'NB08': '9947',\n",
    "  'NB09': '2800',\n",
    "  'NB10': 'G59',\n",
    "  'NB12': 'G62'   # G56 in e-mail Senne\n",
    "}\n",
    "\n",
    "bwa        = '/opt/tools/bwa-0.7.15'\n",
    "samtools   = '/opt/tools/samtools-1.3.1'\n",
    "bcftools   = '/opt/tools/bcftools-1.3.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map amplicons to reference SNP region sequences (51 nt), call variants\n",
    "#\n",
    "for sampleName in sorted(sampleMap):\n",
    "  # Map amplicons\n",
    "  fastqFile = os.path.join(resultDir, '{}.fastq'.format(sampleName))\n",
    "  fastaFile = os.path.join(resultDir, '{}_noqual.fasta'.format(sampleName))\n",
    "  bamFile   = fastaFile.replace('.fasta', '_direct_mapping.bam')\n",
    "  vcfFile   = fastaFile.replace('.fasta', '_direct_mapping.vcf')\n",
    "  \n",
    "  # Convert fastq to fasta\n",
    "  ! paste - - - - < {fastqFile} | cut -f 1,2 | sed 's/^@/>/' | tr \"\\t\" \"\\n\" > {fastaFile}\n",
    "  \n",
    "  # Map\n",
    "  ! {bwa} mem -t 10 -x ont2d {snpRefFile} {fastaFile} | {samtools} view -Sb - | {samtools} sort -o {bamFile} -\n",
    "  ! {samtools} index {bamFile}\n",
    "  \n",
    "  # Variant calling\n",
    "  !{samtools} mpileup -d 100000 -Buf {snpRefFile} -t AD {bamFile} | {bcftools} call -V indels -m - > {vcfFile}\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Detemine the SNP genotype on position 26 in the mappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genotype(vcfFile, snpPos):\n",
    "  \"\"\"\n",
    "  Extract genotype data at given position from a given vcf file.\n",
    "  \"\"\"\n",
    "  genotypeData = {}\n",
    "  \n",
    "  with open (vcfFile, 'rt') as inFile:\n",
    "    for line in inFile:\n",
    "      if line.startswith('#'): continue\n",
    "      \n",
    "      snpName, pos, id, ref, alt, qual, filt, info, form, formValues = line.rstrip().split()\n",
    "      \n",
    "      if int(pos) == snpPos:\n",
    "        k        = form.split(':')\n",
    "        v        = formValues.split(':')         \n",
    "        formData = {}\n",
    "        \n",
    "        for i in range(len(k)):\n",
    "          formData[k[i]] = v[i]\n",
    "          \n",
    "        infoData = {}\n",
    "        for t in info.split(';'):\n",
    "          k,v = t.split('=')\n",
    "          infoData[k] = v\n",
    "          \n",
    "        alleles = ref\n",
    "        if alt != '.':\n",
    "          alleles += ''.join(alt.split(','))\n",
    "          \n",
    "        depths                = [int(d) for d in formData['AD'].split(',')]\n",
    "        gt                    = [alleles[int(i)] for i in formData['GT'].split('/') ]\n",
    "        genotypeData[snpName] = {'pos': pos, 'alleles': {'A': 0, 'G': 0, 'C': 0, 'T':0}, 'genotype': '/'.join(gt), 'depth': int(infoData['DP'])}\n",
    "        \n",
    "        for i in range(len(alleles)):\n",
    "          genotypeData[snpName]['alleles'][alleles[i]] = depths[i]\n",
    "        \n",
    "  return genotypeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all sample genotypes\n",
    "#\n",
    "excludeSnp = [] #['rs9274701'] # Amplicon is found, but content is not as expected\n",
    "genotypes  = {}\n",
    "\n",
    "for sampleName in sorted(sampleMap, key=lambda k: sampleMap[k]):\n",
    "  print(\"SNP's for sample {} ({})\".format(sampleName, sampleMap[sampleName]))\n",
    "  genotypes[sampleName] = {}\n",
    "  vcfFile               = os.path.join(resultDir, '{}_noqual_direct_mapping.vcf'.format(sampleName))\n",
    "  \n",
    "  d = genotype(vcfFile, 26)\n",
    "  \n",
    "  for snpName in sorted(d):\n",
    "    t = sum(d[snpName]['alleles'].values())\n",
    "    \n",
    "    # Likely genotype\n",
    "    gg = {}\n",
    "    vv = sorted([int(c) for c in d[snpName]['alleles'].values()], reverse=True)\n",
    "    \n",
    "    for g, c in d[snpName]['alleles'].items():\n",
    "      if c not in gg:\n",
    "        gg[c] = [g]\n",
    "      else:\n",
    "        gg[c].append(g)\n",
    "    # Second allele must be at least 10% of main allele or it is ignored.\n",
    "    # Third and fourth alleles are always ignored if present.\n",
    "    #if len(vv) > 1 and vv[1] > vv[0]/10:\n",
    "    if len(vv) > 1 and vv[1] > vv[0]/4:\n",
    "      if len(gg[vv[0]]) > 1:\n",
    "        aa = ''.join(gg[vv[0]])\n",
    "      else:\n",
    "        aa = gg[vv[0]][0] + gg[vv[1]][0]\n",
    "    else:\n",
    "      aa = gg[vv[0]][0] + gg[vv[0]][0]\n",
    "    \n",
    "    o = '  {:<14}  '.format(snpName)\n",
    "    \n",
    "    for g in sorted(d[snpName]['alleles']):\n",
    "      o += '  {}:{:<5}'.format(g, d[snpName]['alleles'][g])\n",
    "    for g in sorted(d[snpName]['alleles']):\n",
    "      if t > 0:\n",
    "        o += '  {}:{:>3}%'.format(g, round(100*d[snpName]['alleles'][g]/t))\n",
    "      else:\n",
    "        o += '  {}:{:>3}%'.format(g, '???')\n",
    "    o += '    {:>5}/{:<5} reads'.format(t, d[snpName]['depth'])\n",
    "    o += '    {}'.format(''.join(sorted(aa)))\n",
    "    genotypes[sampleName][snpName] = ''.join(sorted(aa))\n",
    "    print(o)\n",
    "  \n",
    "  print('')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Genotype overview\n",
    "#\n",
    "h = 'SNP           '\n",
    "snpNames = set()\n",
    "\n",
    "sortedSampleNames = sorted(sampleMap, key=lambda k: sampleMap[k])\n",
    "\n",
    "for sampleName in sortedSampleNames:\n",
    "  h += ' {:>10}'.format(sampleMap[sampleName])\n",
    "  \n",
    "  for snpName in genotypes[sampleName]:\n",
    "    snpNames.add(snpName)\n",
    "print(h)\n",
    "\n",
    "for snpName in sorted(snpNames):\n",
    "  r = '{:<14}'.format(snpName)\n",
    "  \n",
    "  for sampleName in sortedSampleNames:\n",
    "    if snpName in genotypes[sampleName]:\n",
    "      aa = ''.join(sorted(genotypes[sampleName][snpName]))\n",
    "    else:\n",
    "      aa = ''\n",
    "    r += ' {:>10}'.format(aa)\n",
    "    \n",
    "    \n",
    "  print(r)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
